{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# IT Academy - Data Science with Python\n",
    "## Sprint 13: Supervised Classification\n",
    "### [Github Supervised Classification](https://github.com/jesussantana/Supervised-Classification)\n",
    "\n",
    "[![forthebadge made-with-python](http://ForTheBadge.com/images/badges/made-with-python.svg)](https://www.python.org/)  \n",
    "[![Made withJupyter](https://img.shields.io/badge/Made%20with-Jupyter-orange?style=for-the-badge&logo=Jupyter)](https://jupyter.org/try)  \n",
    "[![wakatime](https://wakatime.com/badge/github/jesussantana/Supervised-Classification.svg)](https://wakatime.com/badge/github/jesussantana/Supervised-Classification)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data treatment\n",
    "# ==============================================================================\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "from datetime import datetime\n",
    "from tabulate import tabulate\n",
    "import missingno as msno\n",
    "\n",
    "# # Graphics\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from PIL import Image\n",
    "from IPython.display import Image\n",
    "\n",
    "# Preprocessing and modeling\n",
    "# ==============================================================================\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_1samp,ttest_ind\n",
    "from scipy.stats import normaltest\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.stats.mstats import gmean,hmean\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.feature_selection import RFECV, SelectKBest, f_regression\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, euclidean_distances\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet, SGDRegressor\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.plots import plot_convergence\n",
    "\n",
    "# Paralllel Processing\n",
    "# ==============================================================================\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed, dump, load\n",
    "\n",
    "# Various\n",
    "# ==============================================================================\n",
    "import time\n",
    "import random as rd\n",
    "from itertools import product\n",
    "from fitter import Fitter, get_common_distributions\n",
    "\n",
    "# Pandas configuration\n",
    "# ==============================================================================\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Matplotlib configuration\n",
    "# ==============================================================================\n",
    "plt.rcParams['image.cmap'] = \"bwr\"\n",
    "#plt.rcParams['figure.dpi'] = \"100\"\n",
    "plt.rcParams['savefig.bbox'] = \"tight\"\n",
    "style.use('ggplot') or plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "# Seaborn configuration\n",
    "# ==============================================================================\n",
    "sns.set_theme(style='darkgrid', palette='deep')\n",
    "dims = (20, 16)\n",
    "\n",
    "# Warnings configuration\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Folder configuration\n",
    "# ==============================================================================\n",
    "from os import path\n",
    "import sys\n",
    "new_path = '../scripts/'\n",
    "if new_path not in sys.path:\n",
    "    sys.path.append(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path folder configuration\n",
    "# ===============================================================================\n",
    "\n",
    "path = '../data/'\n",
    "file = 'raw/DelayedFlights.csv'\n",
    "\n",
    "df_raw = pd.read_csv(path+file)"
   ]
  },
  {
   "source": [
    "### Exercise 1: \n",
    "  - Create at least three different classification models to try to best predict DelayedFlights.csv flight delay (ArrDelay)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Exercise 2: \n",
    "  - Creates a new variable depending on whether the flight arrived late or not (ArrDelay> 0)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Exercise 3: \n",
    "  - Compare classification models using accuracy, a confidence matrix, and other more advanced metrics."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Exercise 4: \n",
    "  - Train them using the different parameters they support.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Exercise 5: \n",
    "  - Compare your performance using the traint / test approach or using all data (internal validation)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Exercise 5: \n",
    "  - Perform some variable engineering process to improve prediction."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Exercise 6: \n",
    "  - Do not use the DepDelay variable when making predictions."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()"
   ]
  },
  {
   "source": [
    "## Exploratory analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0  Year  Month  DayofMonth  DayOfWeek  DepTime  CRSDepTime  \\\n",
       "0           0  2008      1           3          4   2003.0        1955   \n",
       "1           1  2008      1           3          4    754.0         735   \n",
       "2           2  2008      1           3          4    628.0         620   \n",
       "3           4  2008      1           3          4   1829.0        1755   \n",
       "4           5  2008      1           3          4   1940.0        1915   \n",
       "\n",
       "   ArrTime  CRSArrTime UniqueCarrier  FlightNum TailNum  ActualElapsedTime  \\\n",
       "0   2211.0        2225            WN        335  N712SW              128.0   \n",
       "1   1002.0        1000            WN       3231  N772SW              128.0   \n",
       "2    804.0         750            WN        448  N428WN               96.0   \n",
       "3   1959.0        1925            WN       3920  N464WN               90.0   \n",
       "4   2121.0        2110            WN        378  N726SW              101.0   \n",
       "\n",
       "   CRSElapsedTime  AirTime  ArrDelay  DepDelay Origin Dest  Distance  TaxiIn  \\\n",
       "0           150.0    116.0     -14.0       8.0    IAD  TPA       810     4.0   \n",
       "1           145.0    113.0       2.0      19.0    IAD  TPA       810     5.0   \n",
       "2            90.0     76.0      14.0       8.0    IND  BWI       515     3.0   \n",
       "3            90.0     77.0      34.0      34.0    IND  BWI       515     3.0   \n",
       "4           115.0     87.0      11.0      25.0    IND  JAX       688     4.0   \n",
       "\n",
       "   TaxiOut  Cancelled CancellationCode  Diverted  CarrierDelay  WeatherDelay  \\\n",
       "0      8.0          0                N         0           NaN           NaN   \n",
       "1     10.0          0                N         0           NaN           NaN   \n",
       "2     17.0          0                N         0           NaN           NaN   \n",
       "3     10.0          0                N         0           2.0           0.0   \n",
       "4     10.0          0                N         0           NaN           NaN   \n",
       "\n",
       "   NASDelay  SecurityDelay  LateAircraftDelay  \n",
       "0       NaN            NaN                NaN  \n",
       "1       NaN            NaN                NaN  \n",
       "2       NaN            NaN                NaN  \n",
       "3       0.0            0.0               32.0  \n",
       "4       NaN            NaN                NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Year</th>\n      <th>Month</th>\n      <th>DayofMonth</th>\n      <th>DayOfWeek</th>\n      <th>DepTime</th>\n      <th>CRSDepTime</th>\n      <th>ArrTime</th>\n      <th>CRSArrTime</th>\n      <th>UniqueCarrier</th>\n      <th>FlightNum</th>\n      <th>TailNum</th>\n      <th>ActualElapsedTime</th>\n      <th>CRSElapsedTime</th>\n      <th>AirTime</th>\n      <th>ArrDelay</th>\n      <th>DepDelay</th>\n      <th>Origin</th>\n      <th>Dest</th>\n      <th>Distance</th>\n      <th>TaxiIn</th>\n      <th>TaxiOut</th>\n      <th>Cancelled</th>\n      <th>CancellationCode</th>\n      <th>Diverted</th>\n      <th>CarrierDelay</th>\n      <th>WeatherDelay</th>\n      <th>NASDelay</th>\n      <th>SecurityDelay</th>\n      <th>LateAircraftDelay</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2008</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>2003.0</td>\n      <td>1955</td>\n      <td>2211.0</td>\n      <td>2225</td>\n      <td>WN</td>\n      <td>335</td>\n      <td>N712SW</td>\n      <td>128.0</td>\n      <td>150.0</td>\n      <td>116.0</td>\n      <td>-14.0</td>\n      <td>8.0</td>\n      <td>IAD</td>\n      <td>TPA</td>\n      <td>810</td>\n      <td>4.0</td>\n      <td>8.0</td>\n      <td>0</td>\n      <td>N</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2008</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>754.0</td>\n      <td>735</td>\n      <td>1002.0</td>\n      <td>1000</td>\n      <td>WN</td>\n      <td>3231</td>\n      <td>N772SW</td>\n      <td>128.0</td>\n      <td>145.0</td>\n      <td>113.0</td>\n      <td>2.0</td>\n      <td>19.0</td>\n      <td>IAD</td>\n      <td>TPA</td>\n      <td>810</td>\n      <td>5.0</td>\n      <td>10.0</td>\n      <td>0</td>\n      <td>N</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2008</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>628.0</td>\n      <td>620</td>\n      <td>804.0</td>\n      <td>750</td>\n      <td>WN</td>\n      <td>448</td>\n      <td>N428WN</td>\n      <td>96.0</td>\n      <td>90.0</td>\n      <td>76.0</td>\n      <td>14.0</td>\n      <td>8.0</td>\n      <td>IND</td>\n      <td>BWI</td>\n      <td>515</td>\n      <td>3.0</td>\n      <td>17.0</td>\n      <td>0</td>\n      <td>N</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>2008</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1829.0</td>\n      <td>1755</td>\n      <td>1959.0</td>\n      <td>1925</td>\n      <td>WN</td>\n      <td>3920</td>\n      <td>N464WN</td>\n      <td>90.0</td>\n      <td>90.0</td>\n      <td>77.0</td>\n      <td>34.0</td>\n      <td>34.0</td>\n      <td>IND</td>\n      <td>BWI</td>\n      <td>515</td>\n      <td>3.0</td>\n      <td>10.0</td>\n      <td>0</td>\n      <td>N</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>32.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>2008</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1940.0</td>\n      <td>1915</td>\n      <td>2121.0</td>\n      <td>2110</td>\n      <td>WN</td>\n      <td>378</td>\n      <td>N726SW</td>\n      <td>101.0</td>\n      <td>115.0</td>\n      <td>87.0</td>\n      <td>11.0</td>\n      <td>25.0</td>\n      <td>IND</td>\n      <td>JAX</td>\n      <td>688</td>\n      <td>4.0</td>\n      <td>10.0</td>\n      <td>0</td>\n      <td>N</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.drop(labels='Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.loc[:,[\"ArrDelay\",\"ArrTime\", \"Distance\", \"TaxiIn\", \"TaxiOut\", \"DayOfWeek\", \"DepDelay\",\"CarrierDelay\", 'UniqueCarrier']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1936758 entries, 0 to 1936757\nData columns (total 9 columns):\n #   Column         Dtype  \n---  ------         -----  \n 0   ArrDelay       float64\n 1   ArrTime        float64\n 2   Distance       int64  \n 3   TaxiIn         float64\n 4   TaxiOut        float64\n 5   DayOfWeek      int64  \n 6   DepDelay       float64\n 7   CarrierDelay   float64\n 8   UniqueCarrier  object \ndtypes: float64(6), int64(2), object(1)\nmemory usage: 133.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "source": [
    "- Data sampling to reduce loading time"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=0.001, random_state = 6858)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().sort_values()"
   ]
  },
  {
   "source": [
    "## Distribution of the response variable"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(6, 6))\n",
    "sns.distplot(\n",
    "    df.ArrTime,\n",
    "    hist    = False,\n",
    "    rug     = True,\n",
    "    color   = \"blue\",\n",
    "    kde_kws = {'shade': True, 'linewidth': 1},\n",
    "    ax      = axes[0]\n",
    ")\n",
    "axes[0].set_title(\"Original layout\", fontsize = 'medium')\n",
    "axes[0].set_xlabel('ArrTime', fontsize='small') \n",
    "axes[0].tick_params(labelsize = 6)\n",
    "\n",
    "sns.distplot(\n",
    "    np.sqrt(df.ArrTime),\n",
    "    hist    = False,\n",
    "    rug     = True,\n",
    "    color   = \"blue\",\n",
    "    kde_kws = {'shade': True, 'linewidth': 1},\n",
    "    ax      = axes[1]\n",
    ")\n",
    "axes[1].set_title(\"Square root transformation\", fontsize = 'medium')\n",
    "axes[1].set_xlabel('sqrt(ArrTime)', fontsize='small') \n",
    "axes[1].tick_params(labelsize = 6)\n",
    "\n",
    "sns.distplot(\n",
    "    np.log(df.ArrTime),\n",
    "    hist    = False,\n",
    "    rug     = True,\n",
    "    color   = \"blue\",\n",
    "    kde_kws = {'shade': True, 'linewidth': 1},\n",
    "    ax      = axes[2]\n",
    ")\n",
    "axes[2].set_title(\"Logarithmic transformation\", fontsize = 'medium')\n",
    "axes[2].set_xlabel('log(ArrTime)', fontsize='small') \n",
    "axes[2].tick_params(labelsize = 6)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "source": [
    "## Identify which distribution the data best fit "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions = ['cauchy', 'chi2', 'expon',  'exponpow', 'gamma',\n",
    "                  'norm', 'powerlaw', 'beta', 'logistic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitter = Fitter(df.ArrTime, distributions=distributions)\n",
    "fitter.fit()\n",
    "fitter.summary(Nbest=10, plot=False)"
   ]
  },
  {
   "source": [
    "## Numerical variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes(include=['float64', 'int']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution graph for each numerical variable\n",
    "# ==============================================================================\n",
    "# Adjust number of subplots based on the number of columns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 10))\n",
    "axes = axes.flat\n",
    "columnas_numeric = df.select_dtypes(include=['float64', 'int']).columns\n",
    "columnas_numeric = columnas_numeric.drop('ArrTime')\n",
    "\n",
    "for i, colum in enumerate(columnas_numeric):\n",
    "    sns.histplot(\n",
    "        data    = df,\n",
    "        x       = colum,\n",
    "        stat    = \"count\",\n",
    "        kde     = True,\n",
    "        color   = (list(plt.rcParams['axes.prop_cycle'])*2)[i][\"color\"],\n",
    "        line_kws= {'linewidth': 2},\n",
    "        alpha   = 0.3,\n",
    "        ax      = axes[i]\n",
    "    )\n",
    "    axes[i].set_title(colum, fontsize = 7, fontweight = \"bold\")\n",
    "    axes[i].tick_params(labelsize = 6)\n",
    "    axes[i].set_xlabel(\"\")\n",
    "    \n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(top = 0.9)\n",
    "fig.suptitle('Distribution Numerical Variable', fontsize = 10, fontweight = \"bold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution graph for each numerical variable\n",
    "# ==============================================================================\n",
    "# Adjust number of subplots based on the number of columns\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 10))\n",
    "axes = axes.flat\n",
    "columnas_numeric = df.select_dtypes(include=['float64', 'int']).columns\n",
    "columnas_numeric = columnas_numeric.drop('ArrTime')\n",
    "\n",
    "for i, colum in enumerate(columnas_numeric):\n",
    "    sns.regplot(\n",
    "        x           = df[colum],\n",
    "        y           = df['ArrTime'],\n",
    "        color       = \"gray\",\n",
    "        marker      = '.',\n",
    "        scatter_kws = {\"alpha\":0.4},\n",
    "        line_kws    = {\"color\":\"r\",\"alpha\":0.7},\n",
    "        ax          = axes[i]\n",
    "    )\n",
    "    axes[i].set_title(f\"ArrTime vs {colum}\", fontsize = 7, fontweight = \"bold\")\n",
    "    #axes[i].ticklabel_format(style='sci', scilimits=(-4,4), axis='both')\n",
    "    axes[i].yaxis.set_major_formatter(ticker.EngFormatter())\n",
    "    axes[i].xaxis.set_major_formatter(ticker.EngFormatter())\n",
    "    axes[i].tick_params(labelsize = 6)\n",
    "    axes[i].set_xlabel(\"\")\n",
    "    axes[i].set_ylabel(\"\")\n",
    "\n",
    "    #if (i-1 >= len(columnas_numeric)-1): break\n",
    "\n",
    "# Se eliminan los axes vacíos\n",
    "for i in [8]:\n",
    "    fig.delaxes(axes[i])\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "fig.suptitle('Correlación con ArrTime', fontsize = 10, fontweight = \"bold\")"
   ]
  },
  {
   "source": [
    "## Numerical variables correlation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between numeric columns\n",
    "# ==============================================================================\n",
    "def tidy_corr_matrix(corr_mat):\n",
    "    \n",
    "    # Function to convert a pandas correlation matrix to tidy format\n",
    "    \n",
    "    corr_mat = corr_mat.stack().reset_index()\n",
    "    corr_mat.columns = ['variable_1','variable_2','r']\n",
    "    corr_mat = corr_mat.loc[corr_mat['variable_1'] != corr_mat['variable_2'], :]\n",
    "    corr_mat['abs_r'] = np.abs(corr_mat['r'])\n",
    "    corr_mat = corr_mat.sort_values('abs_r', ascending=False)\n",
    "    \n",
    "    return(corr_mat)\n",
    "\n",
    "\n",
    "\n",
    "corr_matrix = df.select_dtypes(include=['float64', 'int']).corr(method='pearson')\n",
    "tidy_corr_matrix(corr_matrix).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap matrix of correlations\n",
    "# ==============================================================================\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 10))\n",
    "\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    annot     = True,\n",
    "    cbar      = False,\n",
    "    annot_kws = {\"size\": 10},\n",
    "    vmin      = -1,\n",
    "    vmax      = 1,\n",
    "    center    = 0,\n",
    "    cmap      = sns.diverging_palette(20, 220, n=200),\n",
    "    square    = True,\n",
    "    ax        = ax\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation = 45,\n",
    "    horizontalalignment = 'right',\n",
    ")\n",
    "\n",
    "ax.tick_params(labelsize = 11)"
   ]
  },
  {
   "source": [
    "## Qualitative variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qualitative variables (object type)\n",
    "# ============================================================================\n",
    "df.select_dtypes (include = ['object']). describe ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph for each qualitative variable\n",
    "# ==============================================================================\n",
    "# Adjust number of subplots based on the number of columns\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 10))\n",
    "axes = axes.flat\n",
    "columnas_object = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "for i, colum in enumerate(columnas_object):\n",
    "    df[colum].value_counts().plot.barh(ax = axes[i])\n",
    "    axes[i].set_title(colum, fontsize = 10, fontweight = \"bold\")\n",
    "    axes[i].tick_params(labelsize = 11)\n",
    "    axes[i].set_xlabel(\"\")\n",
    "\n",
    "# Empty axes are removed\n",
    "\"\"\"for i in [7, 8]:\n",
    "    fig.delaxes(axes[i])\"\"\"\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "fig.suptitle('Qualitative variable distribution',\n",
    "             fontsize = 11, fontweight = \"bold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph relationship between the price and each qualitative variables\n",
    "# ==============================================================================\n",
    "# Adjust number of subplots based on the number of columns\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 10))\n",
    "axes = axes.flat\n",
    "columnas_object = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "for i, colum in enumerate(columnas_object):\n",
    "    sns.violinplot(\n",
    "        x     = colum,\n",
    "        y     = 'ArrTime',\n",
    "        data  = df,\n",
    "        color = \"white\",\n",
    "        ax    = axes[i]\n",
    "    )\n",
    "    axes[i].set_title(f\"ArrTime vs {colum}\", fontsize = 7, fontweight = \"bold\")\n",
    "    axes[i].yaxis.set_major_formatter(ticker.EngFormatter())\n",
    "    axes[i].tick_params(labelsize = 11)\n",
    "    axes[i].set_xlabel(\"\")\n",
    "    axes[i].set_ylabel(\"\")\n",
    "\n",
    "# Empty axes are removed\n",
    "\"\"\"for i in [7, 8]:\n",
    "    fig.delaxes(axes[i])\"\"\"\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "fig.suptitle('ArrTime distribution by group', fontsize = 10, fontweight = \"bold\")"
   ]
  },
  {
   "source": [
    "## Create Categorical Dummies"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import categorical \n",
    "\n",
    "df = categorical.transform(df, \"UniqueCarrier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imputation of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:] = missing.transform(df[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Divide the data set into training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix\n",
    "X = df.drop('ArrTime', axis = 'columns')\n",
    "# Vector\n",
    "y = df['ArrTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 6858)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\">>>Train partition\")\n",
    "print(\"-----------------------\")\n",
    "print(y_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test partition\")\n",
    "print(\"-----------------------\")\n",
    "print(y_test.describe())"
   ]
  },
  {
   "source": [
    "## Create a Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}